\documentclass[11pt]{article}
\setlength{\topmargin}{-1in}
\setlength{\textheight}{10in}
\setlength{\oddsidemargin}{-0.25in}
\setlength{\textwidth}{7in}
\usepackage{mathpazo}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{appendix}
\usepackage{array}
\usepackage{bm}
\usepackage{cancel}
\usepackage{cite}
\usepackage{courier}
\usepackage{graphicx}
\usepackage{empheq}
\usepackage{enumitem}
\usepackage{listings}
\usepackage{mathtools}
\usepackage{units}
\usepackage{bigstrut}
\usepackage{rotating}
\usepackage{ mathrsfs }
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{setspace}

\pagenumbering{gobble}

\usepackage{floatrow}
\floatsetup[figure]{capposition=top}
\DeclareMathAlphabet{\mathcal}{OMS}{cmsy}{m}{n}

\DeclareMathAlphabet{\mathsfit}{\encodingdefault}{\sfdefault}{m}{}
\SetMathAlphabet{\mathsfit}{bold}{\encodingdefault}{\sfdefault}{bx}{}

\newcommand{\tens}[1]{\bm{\mathsfit{#1}}}

\usepackage{color}
\lstset{language=R,basicstyle=\ttfamily,breaklines=true,
                keywordstyle=\color{blue}\ttfamily,
                stringstyle=\color{red}\ttfamily,
                commentstyle=\color{magenta}\ttfamily,
                showstringspaces=false,
                }

\newcommand*\widefbox[1]{\fbox{\hspace{2em}#1\hspace{2em}}}
\newcommand*\mb{\mathbf}
\newcommand*\reals{\mathbb{R}}
\newcommand*\complex{\mathbb{C}}
\newcommand*\naturals{\mathbb{N}}
\newcommand*\nats{\naturals}
\newcommand*\integers{\mathbb{Z}}
\newcommand*\rationals{\mathbb{Q}}
\newcommand*\irrationals{\mathbb{J}}
\newcommand*\pd{\partial}
\newcommand*\htab{\hspace{4 mm}}
\newcommand*\vtab{\vspace{0.5 in}}
\newcommand*\lsent{\mathcal{L}}
\newcommand*\mean[1]{\overline{#1}}
\newcommand*\union{\cup}
\newcommand*\intersect{\cap}
\newcommand*\cl{\cancel}
\newcommand*\ANS{\text{ANS}}
\newcommand*\As{\text{As}}
\newcommand*\then{\rightarrow}
\newcommand*\elim{\text{E}}
\newcommand*\intro{\text{I}}
\newcommand*\absurd{\curlywedge}
\newcommand*\NK{\vdash_{\text{NK}}}
\newcommand*\interp{\mathcal{I}}
\newcommand*\ba{\[ \begin{aligned}}
\newcommand*\ea{\end{aligned} \]}
\newcommand*\C{\mathcal{C}}
\newcommand*\card[1]{\text{card}\left(#1\right)}
\newcommand*\D{\mathscr{D}}
\newcommand*\df{=_{\text{def}}}
\newcommand*\eps{\epsilon}
\newcommand*\enum{\begin{enumerate}[label=(\alph*)]}
\newcommand*\enumend{\end{enumerate}}
\newcommand*\E[1]{\;\mathsf{E}\left[#1\right]}
\newcommand*\Esub[2]{\mathsf{E}_{#1}\left[#2\right]}
\newcommand*\Var[1]{\;\mathsf{Var}\left(#1\right)}
\newcommand*\SD[1]{\;\mathsf{SD}\left(#1\right)}
\newcommand*\SE[1]{\;\mathsf{SE}\left(#1\right)}
\newcommand*\Cov[1]{\;\mathsf{Cov}\left(#1\right)}
\newcommand*\iid{\overset{\text{iid}}{\sim}}
\newcommand*\Exp[1][\lambda]{\text{Exp}(\text{rate}=#1)}
\newcommand*\ind[1]{\mathbb{1}\left(#1\right)}
\newcommand*\set[1]{\left\{#1\right\}}
\newcommand*\estim[1]{\widehat{#1}}
\newcommand*\der{\text{d}}d
\newcommand*\deriv[2]{\frac{\der #1}{\der #2}}
\newcommand*\pderiv[2]{\frac{\pd #1}{\pd #2}}
\newcommand*\norm[1]{\left\|#1\right\|}
\newcommand*\dist[2]{\;\text{dist}\left(#1, #2\right)}
\newcommand*\interior{\text{int}\;}
\newcommand*\exterior{\text{ext}\;}
\newcommand*\boundary{\text{bd}\;}
\newcommand*\lh{\overset{\text{L'H}}{=}}
\newcommand*\bA{\mathbf{A}}
\newcommand*\bb{\mathbf{b}}
\newcommand*\bB{\mathbf{B}}
\newcommand*\bc{\mathbf{c}}
\newcommand*\bD{\mathbf{D}}
\newcommand*\be{\mathbf{e}}
\newcommand*\bG{\mathbf{G}}
\newcommand*\bh{\mathbf{h}}
\newcommand*\bI{\mathbf{I}}
\newcommand*\bell{\boldsymbol{\ell}}
\newcommand*\bL{\mathbf{L}}
\renewcommand*\bm{\mathbf{m}}
\newcommand*\bo{\mathbf{o}}
\newcommand*\br{\mathbf{r}}
\newcommand*\bs{\mathbf{s}}
\newcommand*\bS{\mathbf{S}}
\newcommand*\bt{\mathbf{t}}
\newcommand*\bu{\mathbf{u}}
\newcommand*\bv{\mathbf{v}}
\newcommand*\bV{\mathbf{V}}
\newcommand*\bx{\mathbf{x}}
\newcommand*\bw{\mathbf{w}}
\newcommand*\bW{\mathbf{W}}
\newcommand*\bX{\mathbf{X}}
\newcommand*\by{\mathbf{y}}
\newcommand*\bY{\mathbf{Y}}
\newcommand*\bZ{\mathbf{Z}}
\newcommand*\bz{\mathbf{z}}
\newcommand*\bp{\mathbf{p}}
\newcommand*\bzero{\mathbf{0}}
\newcommand*\bone{\mathbf{1}}
\newcommand*\balpha{\boldsymbol{\alpha}}
\newcommand*\bbeta{\boldsymbol{\beta}}
\newcommand*\bgamma{\boldsymbol{\gamma}}
\newcommand*\beps{\boldsymbol{\varepsilon}}
\newcommand*\btheta{\boldsymbol{\theta}}
\newcommand*\bTheta{\boldsymbol{\Theta}}
\newcommand*\bmu{\boldsymbol{\mu}}
\newcommand*\bsigma{\boldsymbol{\sigma}}
\newcommand*\bSigma{\boldsymbol{\Sigma}}
\newcommand*\bOmega{\boldsymbol{\Omega}}
\newcommand\Psub[2]{\mathsf{P}_{#1}\left(#2\right)}
\newcommand\Vsub[2]{\mathsf{Var}_{#1}\left(#2\right)}
\newcommand\e{\operatorname{e}}
\newcommand\prox{\operatorname{prox}}
\newcommand\T{\mathsf{T}}

\newread\tmp
\newcommand\getcount{
	\openin\tmp=knot_count.txt
	\read\tmp to \knots
	\closein\tmp
	
	\openin\tmp=span.txt
	\read\tmp to \spanval
	\closein\tmp
	
	\openin\tmp=span_g.txt
	\read\tmp to \spantwo
	\closein\tmp
	
	\openin\tmp=span_g_2.txt
	\read\tmp to \spanthree
	\closein\tmp
}


\renewcommand\Re{\operatorname{Re}}
\renewcommand\Im{\operatorname{Im}}
\DeclareMathOperator*{\argmin}{arg\;min}
\DeclareMathOperator*{\argmax}{arg\;max}
\renewcommand\;{\,}
\renewcommand\epsilon{\varepsilon}
\renewcommand\rho{\varrho}
\renewcommand\phi{\varphi}
\renewcommand\mod{\hspace{0.2em} \textbf{mod}\hspace{0.2em}}
\renewcommand\Pr[1]{ \mathsf{Pr}\left(#1\right) }

\lstset{breaklines=true,
        numbersep=5pt,
        xleftmargin=.25in,
        xrightmargin=.25in}

\DeclareMathOperator{\sech}{sech}
\DeclareMathOperator{\sgn}{sgn}
\makeatletter
\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
  \hskip -\arraycolsep
  \let\@ifnextchar\new@ifnextchar
  \array{#1}}
\makeatother

\newenvironment{amatrix}[1]{%
  \left(\begin{array}{@{}*{#1}{c}|c@{}}
}{%
  \end{array}\right)
}
\vspace{-1in}
\begin{document}
\title{STAT 570: Homework 8}
\author{Branden Olson}
\date{}
\maketitle

\section{}
\enum
\item
We have
\ba
\Var{Y_i} 
	& = \Var{ \sum_{j=1}^{N_i} Z_{ij} } \\
	& = \sum_{j=1}^{N_i} \Var{Z_{ij}}
		+ \sum_{j=1}^{N_i} \sum_{j \ne k} \Cov{Z_{ij}, Z_{jk} } 
\ea
Now,
\ba
	\sum_{i=1}^{N_i}
		\Var{Z_{ij}} & = \sum_{j=1}^{N_i} \left( \E{ Z_{ij}^2 }
		- \E{Z_{ij}}^2 \right) \\
	& = \sum_{j=1}^{N_i} \left(
		\E{Z_{ij}} - \E{Z_{ij}}^2 \right) \htab \because Z_{ij} = Z_{ij}^2
			\htab \because Z_{ij} \in \set{0, 1} \\
	& = N_i \E{Z_{ij}}\left(1 - \E{Z_{ij}}\right) \\
	& = N_i p_i(1 - p_i)
\ea
and
\ba
\Cov{Z_{ij}, Z_{ik}}
	& = \rho_{Z_{ij}, Z_{ik}}
		\sigma_{Z_{ij}} \sigma_{Z_{ik}} \\
	& = \tau_i \Var{Z_{ij}} \\
	& = \tau_i p_i(1 - p_i)
\ea
so that
\ba
\sum_{j=1}^{N_i} \sum_{j \ne k} \Cov{Z_{ij}, Z_{ik}}
	& = \sum_{j=1}^{N_i} (N_i - 1)
		\tau_i p_i(1 - p_i) \\
	& = N_i(N_i - 1) \tau_i p_i(1 - p_i).
\ea
Hence,
\ba
\Var{Y_i}
	& = \sum_{j=1}^{N_i} \Var{Z_{ij}}
		+ \sum_{j=1}^{N_i} \sum_{j \ne k} \Cov{Z_{ij}, Z_{jk} } \\
	& = N_i p_i (1 - p_i)
		+ N_i(N_i - 1) \tau_i p_i(1 - p_i) \\
	& = N_i p_i(1-p_i) \left[ 1 + (N_i - 1) \tau_i \right] \qed
\ea
\item
Here,
\ba
\E{Y_i} & = \E{\E{Y_i | q_i}} \\
	& = \E{ N_i q_i } \\
	& = N_i \E{ q_i } \\
	& = \frac{N_i a_i}{d}
\ea
and
\ba
\Var{Y_i}
	& = \E{\Var{Y_i | q_i}} + \Var{\E{Y_i | q_i}} \\
	& = \E{N_i q_i (1 - q_i)} + \Var{N_i q_i} \\
	& = N_i \left(\E{q_i} - \E{q_i^2}\right) + N_i^2 \Var{q_i} \\
	& = N_i \left(\frac{a_i}{d} - \E{q_i}^2 - \Var{q_i}\right)
		+ N_i^2 \frac{p_i(1 - p_i)}{d + 1} \\
	& = N_i \left(p_i - p_i^2
		- \frac{p_i(1 - p_i)}{d + 1} \right)
		+ \frac{N_i^2 p_i (1 - p_i)}{d + 1} \\
	& = N_i \left(p_i(1 - p_i)
		- \frac{p_i(1 - p_i)}{d + 1} \right)
		+ \frac{N_i^2 p_i (1 - p_i)}{d + 1} \\
	& = N_i p_i(1 - p_i) \left[
		\left(1 - \frac{1}{d+1}\right)
		+ \frac{N_i}{d+1} \right] \\
	& = N_i p_i(1 - p_i) \left[
		1 + (N_i - 1) \cdot  \frac{1}{d+1}\right] \\
\ea
Thus, 
\ba
\boxed{\tau_i^2 = \frac{1}{d + 1}}
\ea
and, using the definitions of $p_i$ and $d$, we can write $\tau^2$ in terms of the original parameters $a_i$ and $b_i$:
\ba
 \tau_i^2 & = \frac{1}{\frac{p_i(1-p_i)}{\Var{q_i}}} \\
 	& = \frac{\Var{q_i}}{\E{q_i}(1 - \E{q_i})} \\
	& = \frac{a_i b_i}{(a_i + b_i)^2(a_i + b_i + 1)}
		\frac{1}{\frac{a_i}{a_i + b_i}\left(1 - \frac{a_i}{a_i + b_i}\right)} \\
	& = \frac{ b_i}{(a_i + b_i)(a_i + b_i + 1) \frac{b_i}{a_i + b_i} } \\
	& = \boxed{ \frac{1}{a_i + b_i + 1} }
\ea

\enumend

\section{}

Binary data, despite their simplicity, can be difficult to model accurately.
In particular, a phenomenon known as overdispersion, in which the data's  variance is larger than what traditional binomial modeling allows, can lead to erroneous standard error estimates. Long and McCullagh present two main model classes that address overdispersed data, discuss their respective strengths and weaknesses, and guide the reader's intuition through multiple case examples from the literature using residual analysis and formal model comparisons as diagnostics.

Often, data transgress the standard binomial assumption, most commonly in the form of overdispersion. The authors introduce various remedies which fall into two categories. First, parametric models can be sought, usually fit via maximum likelihood. A prominent example is the beta-binonial model which generalizes the binomial variance. Unfortunately, these likelihoods are often intractable due to the intricacies that accompany numerical maximization schemes, and also lead to lots of software variants to hack through. Alternatively, parametrics can be avoided by assuming a mean-variance relationship of the data inspired by common distributions. The canonical example of this is quasi-likelihood fitting. This strategy can result in a loss of efficiency, especially if the distribution is strongly believed to match an aforementioned parametric form. Unsurprisingly, the model choice will ultimately come down to the nature of the empirical data.

To assess the nature and level of overdispersion, the authors present two conplimentary techniques. The first is a residual analysis, standardizing the residuals in relation to the index $m$, and looking for evidence of model inconsistencies. The second is a formal comparison of the variance assumptions based on whether the dispersion factor is constant or linearly related to the index size. As expected, the modeling decisions turn out to be highly context-dependent, indicating that the modeler must carefully assess their assumptions before committing to a model incorporating overdispersion. In particular, the diagnostics are most worthwhile for small sample sizes, and should be used in tandem for a more complete picture. 



\end{document}

















